//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_20
.address_size 64

	// .globl	top_level_kernel
.visible .func  (.param .b64 func_retval0) dummy_mul
(
	.param .b64 dummy_mul_param_0,
	.param .b64 dummy_mul_param_1
)
;
.visible .func  (.param .b64 func_retval0) dummy_mul_inner
(
	.param .b64 dummy_mul_inner_param_0,
	.param .b64 dummy_mul_inner_param_1
)
;

.visible .entry top_level_kernel(
	.param .u64 top_level_kernel_param_0,
	.param .u64 top_level_kernel_param_1,
	.param .f64 top_level_kernel_param_2
)
{
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [top_level_kernel_param_0];
	ld.param.u64 	%rd2, [top_level_kernel_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.param.f64 	%fd1, [top_level_kernel_param_2];
	ld.global.f64 	%fd2, [%rd4];
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	dummy_mul, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 7
	mul.rn.f64 	%fd4, %fd3, %fd1;
	st.global.f64 	[%rd3], %fd4;
	ret;
}

	// .globl	dummy_math_kernel
.visible .entry dummy_math_kernel(
	.param .u64 dummy_math_kernel_param_0,
	.param .u64 dummy_math_kernel_param_1
)
{
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [dummy_math_kernel_param_0];
	ld.param.u64 	%rd2, [dummy_math_kernel_param_1];
	cvta.to.global.u64 	%rd3, %rd2;
	cvta.to.global.u64 	%rd4, %rd1;
	ld.global.f64 	%fd1, [%rd4];
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd1;
	.param .b64 retval0;
	call.uni (retval0), 
	dummy_mul, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd2, [retval0+0];
	} // callseq 8
	st.global.f64 	[%rd3], %fd2;
	ret;
}

	// .globl	dummy_mul
.visible .func  (.param .b64 func_retval0) dummy_mul(
	.param .b64 dummy_mul_param_0,
	.param .b64 dummy_mul_param_1
)
{
	.reg .f64 	%fd<4>;

	ld.param.f64 	%fd1, [dummy_mul_param_0];
	ld.param.f64 	%fd2, [dummy_mul_param_1];
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	dummy_mul_inner, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 9
	st.param.f64 	[func_retval0+0], %fd3;
	ret;
}

	// .globl	dummy_mul_inner
.visible .func  (.param .b64 func_retval0) dummy_mul_inner(
	.param .b64 dummy_mul_inner_param_0,
	.param .b64 dummy_mul_inner_param_1
)
{
	.reg .f64 	%fd<4>;

	ld.param.f64 	%fd1, [dummy_mul_inner_param_0];
	ld.param.f64 	%fd2, [dummy_mul_inner_param_1];
	mul.rn.f64 	%fd3, %fd1, %fd2;
	st.param.f64 	[func_retval0+0], %fd3;
	ret;
}

	// .globl	dummy_utils_kernel
.visible .entry dummy_utils_kernel(
	.param .u64 dummy_utils_kernel_param_0,
	.param .u64 dummy_utils_kernel_param_1,
	.param .u64 dummy_utils_kernel_param_2
)
{
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<7>;

	ld.param.u64 	%rd1, [dummy_utils_kernel_param_0];
	ld.param.u64 	%rd2, [dummy_utils_kernel_param_2];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u64 	%rd4, [dummy_utils_kernel_param_1];
	cvta.to.global.u64 	%rd5, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	ld.global.f64 	%fd1, [%rd6];
	ld.global.f64 	%fd2, [%rd5];
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1;
	.param .b64 param1;
	st.param.f64 	[param1+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	dummy_mul, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd3, [retval0+0];
	} // callseq 10
	st.global.f64 	[%rd3], %fd3;
	ret;
}


